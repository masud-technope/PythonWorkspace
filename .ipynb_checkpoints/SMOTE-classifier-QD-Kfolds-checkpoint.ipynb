{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Activation\n",
    "from keras.layers import SimpleRNN, TimeDistributed\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "csv_data=pd.read_csv(\"data/blader-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# csv_data = csv_data.dropna()\n",
    "\n",
    "all_features=csv_data.iloc[:, 0:22]\n",
    "all_labels=csv_data['qclass']\n",
    "\n",
    "encoder.fit(all_labels)\n",
    "all_labels_encoded = encoder.transform(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825 3300\n",
      "        avgIDF    maxIDF    stdIDF   avgICTF   maxICTF   stdICTF  avgEntropy  \\\n",
      "0     0.456622  1.000000  0.228246  0.055738  1.000000  0.179737   -0.106543   \n",
      "1     0.412542  1.000000  0.242443  0.071120  1.000000  0.246478   -0.010079   \n",
      "2     0.425888  1.000000  0.254159  0.080094  1.000000  0.260576   -0.012638   \n",
      "3     0.435027  0.861698  0.205509  0.019730  0.166667  0.043684    0.000000   \n",
      "4     0.394908  0.797440  0.177743  0.008472  0.055556  0.014365    0.000000   \n",
      "5     0.418858  1.000000  0.232085  0.022013  1.000000  0.126779   -0.030336   \n",
      "6     0.492248  1.000000  0.250965  0.045966  1.000000  0.140045   -0.002989   \n",
      "7     0.399338  0.912730  0.296593  0.036525  0.500000  0.116490    0.000000   \n",
      "8     0.380216  0.912730  0.278707  0.031650  0.500000  0.090412    0.000000   \n",
      "9     0.494851  0.912730  0.220209  0.042621  0.500000  0.115085   -0.076846   \n",
      "10    0.388988  0.797440  0.197599  0.013564  0.200000  0.036809   -0.269128   \n",
      "11    0.376401  0.677433  0.191713  0.004446  0.018519  0.005981   -0.021555   \n",
      "12    0.495461  1.000000  0.249269  0.055359  0.500000  0.123548    0.000000   \n",
      "13    0.459990  1.000000  0.229527  0.052460  1.000000  0.164119    0.000000   \n",
      "14    0.415987  1.000000  0.226524  0.022048  1.000000  0.127831    0.000000   \n",
      "15    0.353958  0.912730  0.263753  0.021841  0.500000  0.088038   -0.397018   \n",
      "16    0.427646  0.861698  0.224544  0.018107  0.200000  0.051646   -0.113006   \n",
      "17    0.454080  0.912730  0.265955  0.083971  0.500000  0.176308    0.000000   \n",
      "18    0.435021  0.912730  0.187682  0.007339  0.047619  0.011761   -0.259984   \n",
      "19    0.473337  1.000000  0.216959  0.033226  1.000000  0.123453   -0.007961   \n",
      "20    0.495174  1.000000  0.257155  0.116598  1.000000  0.312166   -0.053103   \n",
      "21    0.395323  0.861698  0.205562  0.015300  0.166667  0.038985   -0.007512   \n",
      "22    0.380600  0.723576  0.211886  0.005034  0.020000  0.007656    0.000000   \n",
      "25    0.571256  0.912730  0.152184  0.021402  0.142857  0.032297   -0.320093   \n",
      "26    0.386955  0.861698  0.211418  0.014014  0.200000  0.045332    0.000000   \n",
      "28    0.462427  1.000000  0.239648  0.091534  1.000000  0.277310   -0.013427   \n",
      "29    0.393763  0.861698  0.206799  0.013346  0.200000  0.044219    0.000000   \n",
      "30    0.458522  1.000000  0.235167  0.058622  1.000000  0.181503   -0.002870   \n",
      "31    0.464943  0.912730  0.230863  0.038784  0.500000  0.105552    0.000000   \n",
      "32    0.367958  0.912730  0.230183  0.008213  0.058824  0.016445   -0.008298   \n",
      "...        ...       ...       ...       ...       ...       ...         ...   \n",
      "3269  0.506675  0.864913  0.209547  0.030465  0.166667  0.055336   -0.335528   \n",
      "3270  0.414385  0.802141  0.159925  0.009802  0.200000  0.027184   -0.129523   \n",
      "3271  0.444018  0.729972  0.192857  0.006921  0.045455  0.012049    0.000000   \n",
      "3272  0.473951  0.914760  0.313266  0.126098  0.500000  0.225476    0.000000   \n",
      "3273  0.504292  1.000000  0.235062  0.085307  1.000000  0.247218   -0.109479   \n",
      "3274  0.363364  1.000000  0.281576  0.085810  1.000000  0.256432    0.000000   \n",
      "3275  0.461563  0.829557  0.215403  0.022839  0.250000  0.048770    0.000000   \n",
      "3276  0.486630  0.914760  0.158744  0.025232  0.500000  0.085825    0.000000   \n",
      "3277  0.444224  0.802141  0.270874  0.019993  0.100000  0.034741   -0.070571   \n",
      "3278  0.367708  0.802141  0.216471  0.018519  0.200000  0.046045    0.000000   \n",
      "3279  0.341293  0.802141  0.213444  0.015542  0.200000  0.042266    0.000000   \n",
      "3280  0.552565  1.000000  0.196185  0.058976  0.500000  0.151562    0.000000   \n",
      "3281  0.427656  1.000000  0.226276  0.057420  1.000000  0.197112    0.000000   \n",
      "3282  0.505287  0.760818  0.138348  0.008983  0.045455  0.014922    0.000000   \n",
      "3283  0.367729  1.000000  0.267450  0.064410  1.000000  0.217636    0.000000   \n",
      "3284  0.552025  0.760818  0.161982  0.011778  0.052632  0.015970   -0.019297   \n",
      "3285  0.489975  1.000000  0.234708  0.064854  1.000000  0.201964    0.000000   \n",
      "3286  0.332549  1.000000  0.199612  0.037453  1.000000  0.172685    0.000000   \n",
      "3287  0.360152  0.864913  0.241708  0.016650  0.200000  0.043978    0.000000   \n",
      "3288  0.427100  1.000000  0.238062  0.035886  1.000000  0.165831   -0.126389   \n",
      "3289  0.387957  0.864913  0.210778  0.011001  0.142857  0.026090   -0.476513   \n",
      "3291  0.489148  0.760818  0.142949  0.008520  0.045455  0.014591    0.000000   \n",
      "3292  0.429113  1.000000  0.228140  0.058477  1.000000  0.198806    0.000000   \n",
      "3293  0.520355  1.000000  0.243822  0.058986  1.000000  0.151602    0.000000   \n",
      "3294  0.381753  1.000000  0.280603  0.093588  1.000000  0.262904    0.000000   \n",
      "3295  0.434631  0.729972  0.202427  0.006608  0.045455  0.012594   -0.346806   \n",
      "3296  0.384618  0.864913  0.211782  0.010572  0.142857  0.025369    0.000000   \n",
      "3297  0.424009  0.864913  0.155055  0.008547  0.125000  0.021977    0.000000   \n",
      "3298  0.557320  1.000000  0.200373  0.061652  0.500000  0.155229    0.000000   \n",
      "3299  0.505172  0.864913  0.224130  0.032607  0.166667  0.055844    0.000000   \n",
      "\n",
      "      maxEntropy  medianEntropy  stdEntropy  ...      sumSCQ    avgSCQ  \\\n",
      "0            0.0       0.000000    0.178485  ...  258.923832  2.563602   \n",
      "1            0.0       0.000000    0.079364  ...  148.566301  2.396231   \n",
      "2            0.0       0.000000    0.093727  ...  130.352012  2.370037   \n",
      "3            0.0       0.000000    0.000000  ...   64.084234  2.670176   \n",
      "4            0.0       0.000000    0.000000  ...   59.302211  2.578357   \n",
      "5            0.0       0.000000    0.126042  ...  165.747382  2.673345   \n",
      "6            0.0       0.000000    0.032609  ...  311.033835  2.613730   \n",
      "7            0.0       0.000000    0.000000  ...   38.411039  2.133947   \n",
      "8            0.0       0.000000    0.000000  ...   93.424052  2.224382   \n",
      "9            0.0       0.000000    0.190479  ...  151.444857  2.753543   \n",
      "10           0.0      -0.300715    0.266521  ...  167.038430  2.530885   \n",
      "11           0.0       0.000000    0.080047  ...   71.702826  2.560815   \n",
      "12           0.0       0.000000    0.000000  ...  232.791494  2.558148   \n",
      "13           0.0       0.000000    0.000000  ...  340.928735  2.544244   \n",
      "14           0.0       0.000000    0.000000  ...  163.152155  2.674625   \n",
      "15           0.0      -0.325635    0.365836  ...   69.746795  2.179587   \n",
      "16           0.0       0.000000    0.168234  ...   74.049289  2.644617   \n",
      "17           0.0       0.000000    0.000000  ...   33.949709  2.263314   \n",
      "18           0.0      -0.296409    0.256468  ...  117.555892  2.798950   \n",
      "19           0.0       0.000000    0.066603  ...  185.434295  2.649061   \n",
      "20           0.0       0.000000    0.136570  ...   72.274988  2.581250   \n",
      "21           0.0       0.000000    0.041138  ...  156.012529  2.557582   \n",
      "22           0.0       0.000000    0.000000  ...   15.291196  2.548533   \n",
      "25           0.0      -0.336481    0.159918  ...   61.753257  3.087663   \n",
      "26           0.0       0.000000    0.000000  ...   93.255173  2.520410   \n",
      "28           0.0       0.000000    0.093028  ...  124.462350  2.592966   \n",
      "29           0.0       0.000000    0.000000  ...  101.527641  2.603273   \n",
      "30           0.0       0.000000    0.023668  ...  343.332860  2.506079   \n",
      "31           0.0       0.000000    0.000000  ...   65.645469  2.625819   \n",
      "32           0.0       0.000000    0.063197  ...  137.917049  2.377880   \n",
      "...          ...            ...         ...  ...         ...       ...   \n",
      "3269         0.0      -0.368819    0.202392  ...  120.761784  2.808414   \n",
      "3270         0.0       0.000000    0.236808  ...  189.603340  2.788284   \n",
      "3271         0.0       0.000000    0.000000  ...   88.510516  2.950351   \n",
      "3272         0.0       0.000000    0.000000  ...   26.906527  2.242211   \n",
      "3273         0.0       0.000000    0.164619  ...   89.962584  2.645958   \n",
      "3274         0.0       0.000000    0.000000  ...   35.894081  1.994116   \n",
      "3275         0.0       0.000000    0.000000  ...   96.147995  2.670778   \n",
      "3276         0.0       0.000000    0.000000  ...  103.832730  2.966649   \n",
      "3277         0.0       0.000000    0.179389  ...   33.544762  2.396054   \n",
      "3278         0.0       0.000000    0.000000  ...  154.945121  2.347653   \n",
      "3279         0.0       0.000000    0.000000  ...   92.924144  2.266443   \n",
      "3280         0.0       0.000000    0.000000  ...   59.536575  2.976829   \n",
      "3281         0.0       0.000000    0.000000  ...  142.762839  2.595688   \n",
      "3282         0.0       0.000000    0.000000  ...   55.966676  3.292157   \n",
      "3283         0.0       0.000000    0.000000  ...   89.765059  2.087560   \n",
      "3284         0.0       0.000000    0.066846  ...   40.220451  3.351704   \n",
      "3285         0.0       0.000000    0.000000  ...   76.143374  2.625634   \n",
      "3286         0.0       0.000000    0.000000  ...   82.382799  2.353794   \n",
      "3287         0.0       0.000000    0.000000  ...   77.160845  2.338207   \n",
      "3288         0.0       0.000000    0.202352  ...   91.537244  2.542701   \n",
      "3289         0.0      -0.512738    0.230380  ...  368.595917  2.559694   \n",
      "3291         0.0       0.000000    0.000000  ...   87.520908  3.241515   \n",
      "3292         0.0       0.000000    0.000000  ...  139.626674  2.585679   \n",
      "3293         0.0       0.000000    0.000000  ...  335.518598  2.727793   \n",
      "3294         0.0       0.000000    0.000000  ...   67.463317  2.044343   \n",
      "3295         0.0      -0.337885    0.236159  ...   76.396005  2.938308   \n",
      "3296         0.0       0.000000    0.000000  ...  396.433293  2.541239   \n",
      "3297         0.0       0.000000    0.000000  ...   88.820927  2.775654   \n",
      "3298         0.0       0.000000    0.000000  ...   56.849985  2.992104   \n",
      "3299         0.0       0.000000    0.000000  ...  149.277638  2.764401   \n",
      "\n",
      "        maxSCQ      avgVAR        sumVAR       maxVAR    avgPMI     maxPMI  \\\n",
      "0     4.106413    2.579073    260.486412   101.480688  0.002264  11.430725   \n",
      "1     3.710561    0.307879     19.088480    19.088480  0.000000   0.000000   \n",
      "2     3.710561    0.032914      1.810255     1.810255  0.000000   0.000000   \n",
      "3     3.891903    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "4     3.737867    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "5     4.232863    6.366420    394.718059   270.368200  0.010209   9.686326   \n",
      "6     4.367297    0.303015     36.058743    36.058743  0.000000   0.000000   \n",
      "7     3.461219    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "8     4.411916    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "9     4.106413    1.385253     76.188888    75.296660  0.009014  13.386520   \n",
      "10    3.848612    8.818145    581.997544    84.707807  0.058473  16.106973   \n",
      "11    3.769475    0.994120     27.835363    26.393181  0.000000   0.000000   \n",
      "12    4.426058    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "13    4.106413    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "14    4.232863    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "15    3.461219    8.426068    269.634180    63.598129  0.296234  10.483123   \n",
      "16    4.068446    3.758276    105.231717    27.468350  0.024352   9.205000   \n",
      "17    3.400936    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "18    4.106413    7.841911    329.360257    79.880264  0.048608  12.311962   \n",
      "19    3.873616    0.491099     34.376924    34.376924  0.000000   0.000000   \n",
      "20    4.106413    1.972640     55.233913    34.041559  0.000000   0.000000   \n",
      "21    4.068446    0.254735     15.538822     7.769411  0.000000   0.000000   \n",
      "22    3.554223    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "25    3.849733   16.965442    339.308845   115.381996  0.412492  12.909116   \n",
      "26    3.581558    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "28    4.106413    0.192566      9.243190     9.243190  0.000000   0.000000   \n",
      "29    4.068446    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "30    3.873616    0.001485      0.203491     0.101746  0.000000   0.000000   \n",
      "31    4.347436    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "32    4.232329    0.840381     48.742123    48.742123  0.000000   0.000000   \n",
      "...        ...         ...           ...          ...       ...        ...   \n",
      "3269  3.683069   19.534826    839.997511   245.839248  0.199401  14.592459   \n",
      "3270  3.922521    0.456284     31.027311     4.577857  0.004913  11.190876   \n",
      "3271  4.800258    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3272  3.939366    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3273  3.408568    0.691017     23.494579     5.585268  0.025556  14.337055   \n",
      "3274  3.168446    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3275  3.878438    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3276  4.137440    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3277  3.412322    0.421615      5.902606     2.951303  0.000000   0.000000   \n",
      "3278  3.462525    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3279  3.462525    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3280  3.844677    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3281  3.414904    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3282  3.776854    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3283  3.447235    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3284  3.965253    0.152402      1.828825     1.828825  0.000000   0.000000   \n",
      "3285  3.408568    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3286  3.337571    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3287  3.802504    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3288  3.710273    2.706811     97.445186    25.156998  0.035047  12.209390   \n",
      "3289  3.974492  108.891588  15680.388653  1351.021662  0.026786  13.182873   \n",
      "3291  3.776854    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3292  3.414904    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3293  5.182263    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3294  3.168446    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3295  4.800258  292.689567   7609.928732  3074.359428  0.308188  11.687583   \n",
      "3296  3.974492    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3297  3.451697    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3298  3.844677    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "3299  3.683069    0.000000      0.000000     0.000000  0.000000   0.000000   \n",
      "\n",
      "            HS           PA  \n",
      "0     0.389683    83.962927  \n",
      "1     0.475767  5891.048695  \n",
      "2     0.471189  3863.954964  \n",
      "3     0.480269   389.699943  \n",
      "4     0.528757  1298.321072  \n",
      "5     0.479942   117.363456  \n",
      "6     0.475303  1332.567879  \n",
      "7     0.490930   657.931138  \n",
      "8     0.498301  1465.561729  \n",
      "9     0.466425   422.467246  \n",
      "10    0.520110  1203.950549  \n",
      "11    0.488596    25.025491  \n",
      "12    0.505569   285.585194  \n",
      "13    0.371247  2033.841816  \n",
      "14    0.483593   485.567908  \n",
      "15    0.541764  3685.256499  \n",
      "16    0.579923   468.045183  \n",
      "17    0.534405     5.552197  \n",
      "18    0.509098  2734.933151  \n",
      "19    0.448687  1410.479727  \n",
      "20    0.506294   171.589919  \n",
      "21    0.470862   195.805503  \n",
      "22    0.427554   590.183432  \n",
      "25    0.562849   571.122230  \n",
      "26    0.536299    24.390016  \n",
      "28    0.477292    19.721771  \n",
      "29    0.538297  1080.450610  \n",
      "30    0.364904  2041.519013  \n",
      "31    0.452489   393.696358  \n",
      "32    0.473847   441.317074  \n",
      "...        ...          ...  \n",
      "3269  0.572728  5997.248603  \n",
      "3270  0.463774  1868.802701  \n",
      "3271  0.474983   166.156538  \n",
      "3272  0.505043   514.996002  \n",
      "3273  0.539575    63.590233  \n",
      "3274  0.547421   572.569462  \n",
      "3275  0.547876   683.688016  \n",
      "3276  0.486319   542.493379  \n",
      "3277  0.488294   264.670076  \n",
      "3278  0.519332   194.786295  \n",
      "3279  0.508923    17.535103  \n",
      "3280  0.507189    35.357767  \n",
      "3281  0.500772   332.677207  \n",
      "3282  0.503925  1618.957724  \n",
      "3283  0.502949    23.544691  \n",
      "3284  0.499658   126.101868  \n",
      "3285  0.523283   137.040123  \n",
      "3286  0.489573  1533.882152  \n",
      "3287  0.490903  2916.447482  \n",
      "3288  0.522862  1117.751928  \n",
      "3289  0.514726  2707.398389  \n",
      "3291  0.506939  1618.957724  \n",
      "3292  0.500291   332.677207  \n",
      "3293  0.586060  2901.847787  \n",
      "3294  0.537531   780.378959  \n",
      "3295  0.503433   166.156538  \n",
      "3296  0.504342  2707.398389  \n",
      "3297  0.501465  2416.061876  \n",
      "3298  0.506946    35.357767  \n",
      "3299  0.545408   425.146174  \n",
      "\n",
      "[2969 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "all_features.head()\n",
    "print(all_labels_encoded.sum(), len(all_labels_encoded))\n",
    "print(all_features.iloc[train,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    \n",
    "    # Begin CHANGES\n",
    "    fst_empty_cell = (columnwidth-3)//2 * \" \" + \"t/p\" + (columnwidth-3)//2 * \" \"\n",
    "    \n",
    "    if len(fst_empty_cell) < len(empty_cell):\n",
    "        fst_empty_cell = \" \" * (len(empty_cell) - len(fst_empty_cell)) + fst_empty_cell\n",
    "    # Print header\n",
    "    print(\"    \" + fst_empty_cell, end=\" \")\n",
    "    # End CHANGES\n",
    "    \n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "        \n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\programdata\\anaconda3\\envs\\graphembed\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\graphembed\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=2)`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 74.92%\n",
      "acc: 74.92%\n",
      "acc: 74.92%\n",
      "acc: 75.23%\n",
      "acc: 74.92%\n",
      "acc: 75.08%\n",
      "acc: 75.08%\n",
      "acc: 75.08%\n",
      "acc: 75.08%\n",
      "acc: 75.08%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-335bc859213a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mcvscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%.2f%% (+/- %.2f%%)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcvscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcvscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "#do the sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "    \n",
    "seed=100\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kfold.split(all_features, all_labels_encoded):\n",
    "  # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,input_shape=(22,)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    model.add(Dense(output_dim=2))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    # make the cateories for labels\n",
    "    \n",
    "    test_one_hot_labels = keras.utils.to_categorical(all_labels_encoded[test], num_classes=2)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    sm=SMOTE()\n",
    "    X_train_sampled, Y_train_sampled = sm.fit_sample(all_features.iloc[train,:], all_labels[train])\n",
    "    \n",
    "    #encode the labels\n",
    "    train_one_hot_labels = keras.utils.to_categorical(all_labels_encoded[train], num_classes=2)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train_sampled, train_one_hot_labels, epochs=823, batch_size=32, verbose=0)\n",
    "    \n",
    "    \n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(all_features.iloc[test,:], test_one_hot_labels, verbose=0)\n",
    "    \n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    \n",
    "    predictions=model.predict(all_features.iloc[test,:])\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    matrix = confusion_matrix(test_one_hot_labels.argmax(axis=1), predictions.argmax(axis=1), labels=[0,1])\n",
    "    print_cm(matrix, [\"0\",\"1\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.03% (+/- 0.10%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
