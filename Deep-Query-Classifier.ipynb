{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation,Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import SimpleRNN, TimeDistributed\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import History\n",
    "\n",
    "from keras import losses\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Bug bot improve documentation feedback error h...\n",
      "1    Bug Remotesvcs OSGi ServiceUIComponent violate...\n",
      "2    Bug org eclipse ecf internal discovery Discove...\n",
      "3         Bug Discovery JmDNS Timer canceled early DNS\n",
      "4                        Bug IRC tab completion broken\n",
      "Name: query, dtype: object\n",
      "0    good\n",
      "1    good\n",
      "2    good\n",
      "3    good\n",
      "4    good\n",
      "Name: classlabel, dtype: object\n"
     ]
    }
   ],
   "source": [
    "csv_data_df=pd.read_csv(\"query-data/br-query-corpus.csv\", encoding='latin-1')\n",
    "# csv_data_df = shuffle(csv_data_df)\n",
    "features = csv_data_df.iloc[:, 0]\n",
    "print(features.head())\n",
    "classes = csv_data_df.iloc[:, 1]\n",
    "print(classes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the texts to number\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(features)\n",
    "X = tokenizer.texts_to_sequences(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_labels(yvalues):\n",
    "    values = array(yvalues)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories=\"auto\")\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded_labels = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=get_encoded_labels(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 878, 414, 879, 1584, 6, 227]\n",
      "[0. 1.]\n",
      "3498\n"
     ]
    }
   ],
   "source": [
    "#showing the tokenized features and classes\n",
    "print(X[0])\n",
    "print(Y[0])\n",
    "\n",
    "print(len(tokenizer.index_word))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum review length: 25\n"
     ]
    }
   ],
   "source": [
    "print('Maximum review length: {}'.format(\n",
    "len(max((X), key=len))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    1 1119  121 1585  880 1120   67 1586]\n"
     ]
    }
   ],
   "source": [
    "#padding the queries \n",
    "max_words=25\n",
    "\n",
    "#padding the documents\n",
    "from keras.preprocessing import sequence\n",
    "padded_X = sequence.pad_sequences(X, maxlen=max_words)\n",
    "\n",
    "print(padded_X[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#developing training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(padded_X, Y, test_size=.20, random_state=100)\n",
    "x_train.shape[1], y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 25, 100)           350000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 430,608\n",
      "Trainable params: 430,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#constructing the LSTM model\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "embedding_size=100\n",
    "vocabulary_size=3500\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(2, activation=\"relu\"))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training\n",
    "batch_size = 32\n",
    "num_epochs = 25\n",
    "\n",
    "x_valid, y_valid = x_train[:batch_size], y_train[:batch_size]\n",
    "x_train2, y_train2 = x_train[batch_size:], y_train[batch_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   39,\n",
       "       3128,   58, 3129])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid[0]\n",
    "# y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\masudrahman\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1824 samples, validate on 32 samples\n",
      "Epoch 1/25\n",
      "1824/1824 [==============================] - 2s 955us/step - loss: 0.6904 - accuracy: 0.5872 - val_loss: 0.7002 - val_accuracy: 0.4219\n",
      "Epoch 2/25\n",
      "1824/1824 [==============================] - 1s 694us/step - loss: 0.6401 - accuracy: 0.6859 - val_loss: 0.8472 - val_accuracy: 0.4531\n",
      "Epoch 3/25\n",
      "1824/1824 [==============================] - 1s 769us/step - loss: 0.4909 - accuracy: 0.7867 - val_loss: 0.7986 - val_accuracy: 0.5625\n",
      "Epoch 4/25\n",
      "1824/1824 [==============================] - 1s 764us/step - loss: 0.3168 - accuracy: 0.8857 - val_loss: 1.0589 - val_accuracy: 0.6094\n",
      "Epoch 5/25\n",
      "1824/1824 [==============================] - 1s 723us/step - loss: 0.1847 - accuracy: 0.9378 - val_loss: 1.2604 - val_accuracy: 0.6094\n",
      "Epoch 6/25\n",
      "1824/1824 [==============================] - 2s 917us/step - loss: 0.1009 - accuracy: 0.9679 - val_loss: 1.4379 - val_accuracy: 0.5625\n",
      "Epoch 7/25\n",
      "1824/1824 [==============================] - 2s 1ms/step - loss: 0.0959 - accuracy: 0.9671 - val_loss: 2.0292 - val_accuracy: 0.5469\n",
      "Epoch 8/25\n",
      "1824/1824 [==============================] - 2s 852us/step - loss: 0.0467 - accuracy: 0.9849 - val_loss: 2.5941 - val_accuracy: 0.5312\n",
      "Epoch 9/25\n",
      "1824/1824 [==============================] - 2s 1ms/step - loss: 0.0353 - accuracy: 0.9907 - val_loss: 2.5204 - val_accuracy: 0.5625\n",
      "Epoch 10/25\n",
      "1824/1824 [==============================] - 2s 934us/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 3.1266 - val_accuracy: 0.5312\n",
      "Epoch 11/25\n",
      "1824/1824 [==============================] - 1s 690us/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 3.0972 - val_accuracy: 0.5625\n",
      "Epoch 12/25\n",
      "1824/1824 [==============================] - 1s 693us/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 3.0489 - val_accuracy: 0.5625\n",
      "Epoch 13/25\n",
      "1824/1824 [==============================] - 1s 686us/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 3.5626 - val_accuracy: 0.4688\n",
      "Epoch 14/25\n",
      "1824/1824 [==============================] - 1s 748us/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 3.4438 - val_accuracy: 0.4844\n",
      "Epoch 15/25\n",
      "1824/1824 [==============================] - 1s 694us/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 3.5910 - val_accuracy: 0.5312\n",
      "Epoch 16/25\n",
      "1824/1824 [==============================] - 1s 689us/step - loss: 0.0064 - accuracy: 0.9975 - val_loss: 3.4624 - val_accuracy: 0.5469\n",
      "Epoch 17/25\n",
      "1824/1824 [==============================] - 1s 731us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.7241 - val_accuracy: 0.5469\n",
      "Epoch 18/25\n",
      "1824/1824 [==============================] - 1s 775us/step - loss: 6.6215e-04 - accuracy: 1.0000 - val_loss: 4.0361 - val_accuracy: 0.5625\n",
      "Epoch 19/25\n",
      "1824/1824 [==============================] - 2s 1ms/step - loss: 3.5288e-04 - accuracy: 1.0000 - val_loss: 4.2167 - val_accuracy: 0.5469\n",
      "Epoch 20/25\n",
      "1824/1824 [==============================] - 2s 933us/step - loss: 2.6006e-04 - accuracy: 1.0000 - val_loss: 4.3425 - val_accuracy: 0.5469\n",
      "Epoch 21/25\n",
      "1824/1824 [==============================] - 2s 941us/step - loss: 2.0911e-04 - accuracy: 1.0000 - val_loss: 4.4493 - val_accuracy: 0.5469\n",
      "Epoch 22/25\n",
      "1824/1824 [==============================] - 2s 884us/step - loss: 1.6865e-04 - accuracy: 1.0000 - val_loss: 4.5430 - val_accuracy: 0.5312\n",
      "Epoch 23/25\n",
      "1824/1824 [==============================] - 1s 754us/step - loss: 1.4451e-04 - accuracy: 1.0000 - val_loss: 4.6158 - val_accuracy: 0.5469\n",
      "Epoch 24/25\n",
      "1824/1824 [==============================] - 1s 693us/step - loss: 1.2542e-04 - accuracy: 1.0000 - val_loss: 4.6806 - val_accuracy: 0.5312\n",
      "Epoch 25/25\n",
      "1824/1824 [==============================] - 2s 963us/step - loss: 1.1017e-04 - accuracy: 1.0000 - val_loss: 4.7427 - val_accuracy: 0.5312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2711adafa48>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the model\n",
    "model.fit(x_train2, y_train2, validation_data=(x_valid, y_valid), \n",
    "          batch_size=batch_size, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
